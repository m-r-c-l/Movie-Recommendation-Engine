{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7801a195",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622aabcc",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3026dc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ff2c7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "153294b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-05 23:37:51.189961: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-05 23:37:51.217510: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-05 23:37:51.217540: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-05 23:37:51.218652: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-05 23:37:51.223754: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-05 23:37:51.224399: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-05 23:37:52.119907: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_recommenders as tfrs\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0127d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dfacb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8469e27b",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85378c1",
   "metadata": {},
   "source": [
    "Documentation for datasets: https://www.tensorflow.org/datasets/catalog/movielens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a596e13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ratings data.\n",
    "ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\")\n",
    "# Features of all the available movies.\n",
    "movies = tfds.load(\"movielens/100k-movies\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005ae197",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb18918e",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Transform tfds to dataframe for exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55c9859",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ratings_df = tfds.as_dataframe(ratings)\n",
    "movies_df = tfds.as_dataframe(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81fb601",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ratings_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d1cdbe",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "movies_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc91b9ef",
   "metadata": {},
   "source": [
    "### Create mapping of relevant features from the tfds for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "445b4d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings.map(lambda x: {\n",
    "    \"movie_title\": x[\"movie_title\"],\n",
    "    \"user_id\": x[\"user_id\"],\n",
    "    \"user_rating\": float(x[\"user_rating\"])\n",
    "})\n",
    "movies = movies.map(lambda x: x[\"movie_title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dc04406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.map_op._MapDataset"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae07695a",
   "metadata": {},
   "source": [
    "# The model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abea8b7a",
   "metadata": {},
   "source": [
    "## Shuffle, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b3808b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Data: 100000\n"
     ]
    }
   ],
   "source": [
    "print('Total Data: {}'.format(len(ratings)))\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = ratings.take(800_000)\n",
    "test = ratings.skip(800_000).take(200_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e59bc5",
   "metadata": {},
   "source": [
    "## Create batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3764e244",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_titles = movies.batch(1_024)\n",
    "user_ids = ratings.batch(1_024).map(lambda x: x[\"user_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b7bf1f",
   "metadata": {},
   "source": [
    "## Get unique user_ids and movie_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba00614",
   "metadata": {},
   "source": [
    "... to later convert each user_id and movie_title to a unique integer index for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3eaa4b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_movie_titles = np.unique(np.concatenate(list(movie_titles)))\n",
    "unique_user_ids = np.unique(np.concatenate(list(user_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8080a791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Movies: 1664\n",
      "Unique users: 943\n"
     ]
    }
   ],
   "source": [
    "print('Unique Movies: {}'.format(len(unique_movie_titles)))\n",
    "print('Unique users: {}'.format(len(unique_user_ids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f765cfb0",
   "metadata": {},
   "source": [
    "## The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "85cd4750",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 47)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m<tokenize>:47\u001b[0;36m\u001b[0m\n\u001b[0;31m    def call(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "class MovieModel(tfrs.models.Model):\n",
    "\n",
    "    def __init__(self, movies, unique_movie_titles, unique_user_ids, rating_weight: float, retrieval_weight: float, seed=42) -> None:\n",
    "        # We take the loss weights in the constructor: this allows us to instantiate\n",
    "        # several model objects with different loss weights.\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        embedding_dimension = 32\n",
    "\n",
    "        # User and movie models.\n",
    "        self.movie_model: tf.keras.layers.Layer = tf.keras.Sequential([\n",
    "          tf.keras.layers.StringLookup(\n",
    "            vocabulary=unique_movie_titles, mask_token=None),\n",
    "          tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding_dimension)\n",
    "        ])\n",
    "        self.user_model: tf.keras.layers.Layer = tf.keras.Sequential([\n",
    "          tf.keras.layers.StringLookup(\n",
    "            vocabulary=unique_user_ids, mask_token=None),\n",
    "          tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "        ])\n",
    "\n",
    "        # A small model to take in user and movie embeddings and predict ratings.\n",
    "        # We can make this as complicated as we want as long as we output a scalar\n",
    "        # as our prediction.\n",
    "        self.rating_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(1),\n",
    "        ])\n",
    "\n",
    "        # The tasks.\n",
    "        self.rating_task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
    "            loss=tf.keras.losses.MeanSquaredError(),\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError()],\n",
    "        )\n",
    "        self.retrieval_task: tf.keras.layers.Layer = tfrs.tasks.Retrieval(\n",
    "            metrics=tfrs.metrics.FactorizedTopK(\n",
    "                candidates=movies.batch(128).map(self.movie_model)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # The loss weights.\n",
    "        self.rating_weight = rating_weight\n",
    "        self.retrieval_weight = retrieval_weight\n",
    "\n",
    "    def call(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\n",
    "        # We pick out the user features and pass them into the user model.\n",
    "        user_embeddings = self.user_model(features[\"user_id\"])\n",
    "        # And pick out the movie features and pass them into the movie model.\n",
    "        movie_embeddings = self.movie_model(features[\"movie_title\"])\n",
    "\n",
    "        return (\n",
    "            user_embeddings,\n",
    "            movie_embeddings,\n",
    "            # We apply the multi-layered rating model to a concatentation of\n",
    "            # user and movie embeddings.\n",
    "            self.rating_model(\n",
    "                tf.concat([user_embeddings, movie_embeddings], axis=1)\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "\n",
    "        ratings = features.pop(\"user_rating\")\n",
    "\n",
    "        user_embeddings, movie_embeddings, rating_predictions = self(features)\n",
    "\n",
    "        # We compute the loss for each task.\n",
    "        rating_loss = self.rating_task(\n",
    "            labels=ratings,\n",
    "            predictions=rating_predictions,\n",
    "        )\n",
    "        retrieval_loss = self.retrieval_task(user_embeddings, movie_embeddings)\n",
    "\n",
    "        # And combine them using the loss weights.\n",
    "        return (self.rating_weight * rating_loss\n",
    "                + self.retrieval_weight * retrieval_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d75892",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieModel(tfrs.models.Model):\n",
    "\n",
    "    def __init__(self, movies, unique_movie_titles, unique_user_ids, rating_weight: float, retrieval_weight: float, seed=42) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        embedding_dimension = 64\n",
    "\n",
    "        # Seeded initializers for embeddings to ensure determinism\n",
    "        embedding_initializer = tf.keras.initializers.GlorotUniform(seed=seed)\n",
    "\n",
    "        # User and movie models.\n",
    "        self.movie_model: tf.keras.layers.Layer = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(\n",
    "                vocabulary=unique_movie_titles, mask_token=None),\n",
    "            tf.keras.layers.Embedding(\n",
    "                len(unique_movie_titles) + 1,\n",
    "                embedding_dimension,\n",
    "                embeddings_initializer=embedding_initializer  # Seeded initializer\n",
    "            )\n",
    "        ])\n",
    "        self.user_model: tf.keras.layers.Layer = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(\n",
    "                vocabulary=unique_user_ids, mask_token=None),\n",
    "            tf.keras.layers.Embedding(\n",
    "                len(unique_user_ids) + 1,\n",
    "                embedding_dimension,\n",
    "                embeddings_initializer=embedding_initializer  # Seeded initializer\n",
    "            )\n",
    "        ])\n",
    "\n",
    "        # A small model to take in user and movie embeddings and predict ratings.\n",
    "        self.rating_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(256, activation=\"relu\", kernel_initializer=tf.keras.initializers.GlorotUniform(seed=seed)),\n",
    "            tf.keras.layers.Dense(128, activation=\"relu\", kernel_initializer=tf.keras.initializers.GlorotUniform(seed=seed)),\n",
    "            tf.keras.layers.Dense(1, kernel_initializer=tf.keras.initializers.GlorotUniform(seed=seed)),\n",
    "        ])\n",
    "\n",
    "        # The tasks.\n",
    "        self.rating_task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
    "            loss=tf.keras.losses.MeanSquaredError(),\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError()],\n",
    "        )\n",
    "        self.retrieval_task: tf.keras.layers.Layer = tfrs.tasks.Retrieval(\n",
    "            metrics=tfrs.metrics.FactorizedTopK(\n",
    "                candidates=movies.batch(128).map(self.movie_model)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # The loss weights.\n",
    "        self.rating_weight = rating_weight\n",
    "        self.retrieval_weight = retrieval_weight\n",
    "\n",
    "    def call(self, features: dict) -> tf.Tensor:\n",
    "        # Extract user and movie features and pass them to the respective models.\n",
    "        user_embeddings = self.user_model(features[\"user_id\"])\n",
    "        movie_embeddings = self.movie_model(features[\"movie_title\"])\n",
    "\n",
    "        # Concatenate user and movie embeddings and pass through the rating model.\n",
    "        return (\n",
    "            user_embeddings,\n",
    "            movie_embeddings,\n",
    "            self.rating_model(\n",
    "                tf.concat([user_embeddings, movie_embeddings], axis=1)\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def compute_loss(self, features: dict, training=False) -> tf.Tensor:\n",
    "        ratings = features.pop(\"user_ratings\")\n",
    "\n",
    "        user_embeddings, movie_embeddings, rating_predictions = self(features)\n",
    "\n",
    "        # Compute loss for both tasks (ranking and retrieval).\n",
    "        rating_loss = self.rating_task(\n",
    "            labels=ratings,\n",
    "            predictions=rating_predictions,\n",
    "        )\n",
    "        retrieval_loss = self.retrieval_task(user_embeddings, movie_embeddings)\n",
    "\n",
    "        # Combine the losses using the specified weights.\n",
    "        return (self.rating_weight * rating_loss\n",
    "                + self.retrieval_weight * retrieval_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6097ca96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieModel(tfrs.models.Model):\n",
    "\n",
    "  def __init__(self, rating_weight: float, retrieval_weight: float) -> None:\n",
    "    # We take the loss weights in the constructor: this allows us to instantiate\n",
    "    # several model objects with different loss weights.\n",
    "\n",
    "    super().__init__()\n",
    "\n",
    "    embedding_dimension = 64\n",
    "\n",
    "    # User and movie models.\n",
    "    self.movie_model: tf.keras.layers.Layer = tf.keras.Sequential([\n",
    "      tf.keras.layers.StringLookup(\n",
    "        vocabulary=unique_movie_titles, mask_token=None),\n",
    "      tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding_dimension)\n",
    "    ])\n",
    "    self.user_model: tf.keras.layers.Layer = tf.keras.Sequential([\n",
    "      tf.keras.layers.StringLookup(\n",
    "        vocabulary=unique_user_ids, mask_token=None),\n",
    "      tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "    ])\n",
    "\n",
    "    # A small model to take in user and movie embeddings and predict ratings.\n",
    "    # We can make this as complicated as we want as long as we output a scalar\n",
    "    # as our prediction.\n",
    "    self.rating_model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(1),\n",
    "    ])\n",
    "\n",
    "    # The tasks.\n",
    "    self.rating_task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
    "        loss=tf.keras.losses.MeanSquaredError(),\n",
    "        metrics=[tf.keras.metrics.RootMeanSquaredError()],\n",
    "    )\n",
    "    self.retrieval_task: tf.keras.layers.Layer = tfrs.tasks.Retrieval(\n",
    "        metrics=tfrs.metrics.FactorizedTopK(\n",
    "            candidates=movies.batch(128).map(self.movie_model)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # The loss weights.\n",
    "    self.rating_weight = rating_weight\n",
    "    self.retrieval_weight = retrieval_weight\n",
    "\n",
    "  def call(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\n",
    "    # We pick out the user features and pass them into the user model.\n",
    "    user_embeddings = self.user_model(features[\"user_id\"])\n",
    "    # And pick out the movie features and pass them into the movie model.\n",
    "    movie_embeddings = self.movie_model(features[\"movie_title\"])\n",
    "    \n",
    "    return (\n",
    "        user_embeddings,\n",
    "        movie_embeddings,\n",
    "        # We apply the multi-layered rating model to a concatentation of\n",
    "        # user and movie embeddings.\n",
    "        self.rating_model(\n",
    "            tf.concat([user_embeddings, movie_embeddings], axis=1)\n",
    "        ),\n",
    "    )\n",
    "\n",
    "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "\n",
    "    ratings = features.pop(\"user_ratings\")\n",
    "\n",
    "    user_embeddings, movie_embeddings, rating_predictions = self(features)\n",
    "\n",
    "    # We compute the loss for each task.\n",
    "    rating_loss = self.rating_task(\n",
    "        labels=ratings,\n",
    "        predictions=rating_predictions,\n",
    "    )\n",
    "    retrieval_loss = self.retrieval_task(user_embeddings, movie_embeddings)\n",
    "\n",
    "    # And combine them using the loss weights.\n",
    "    return (self.rating_weight * rating_loss\n",
    "            + self.retrieval_weight * retrieval_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc678f50",
   "metadata": {},
   "source": [
    "## Fitting and evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "74eb1846",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MovieModel(rating_weight=1.0, retrieval_weight=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bba7e75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8599ef27",
   "metadata": {},
   "source": [
    "## Shuffle, batch and cache the training and evaluation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0b10eae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_train = train.batch(1_024).cache()\n",
    "cached_test = test.batch(1_024).cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807ab722",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18172b3",
   "metadata": {},
   "source": [
    "def train_model():\n",
    "    history = model.fit(cached_train, epochs=3)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9f51a5",
   "metadata": {},
   "source": [
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0647d9be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 9s 81ms/step - root_mean_squared_error: 1.1965 - factorized_top_k/top_1_categorical_accuracy: 2.2000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0086 - factorized_top_k/top_10_categorical_accuracy: 0.0204 - factorized_top_k/top_50_categorical_accuracy: 0.1094 - factorized_top_k/top_100_categorical_accuracy: 0.2012 - loss: 6948.9847 - regularization_loss: 0.0000e+00 - total_loss: 6948.9847\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f7634200a60>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(cached_train, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7410939",
   "metadata": {},
   "source": [
    "## Evaluate the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbf8a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = model.evaluate(cached_test, return_dict=True)\n",
    "\n",
    "print(f\"\\nRetrieval top-100 accuracy: {metrics['factorized_top_k/top_100_categorical_accuracy']:.3f}\")\n",
    "print(f\"Ranking RMSE: {metrics['root_mean_squared_error']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4012e2",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fdd6031a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow_recommenders.layers.factorized_top_k.BruteForce'>\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpba3typxi/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpba3typxi/model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 recommendations for user 13:\n",
      "\n",
      "1. Ice Storm, The (1997)\n",
      "2. Ice Storm, The (1997)\n",
      "3. Money Talks (1997)\n",
      "4. Money Talks (1997)\n",
      "5. Desperate Measures (1998)\n"
     ]
    }
   ],
   "source": [
    "predict_movie(13, top_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "866760eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ratings = pd.DataFrame({\n",
    "    'movie': ['Movie 1', 'Movie 2', 'Movie 3', 'Movie 4'],\n",
    "    'rating': [5, 4, 5, 2]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d096cfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_to_id = {\n",
    "    'Movie 1': 1,\n",
    "    'Movie 2': 2,\n",
    "    'Movie 3': 3,\n",
    "    'Movie 4': 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7350b993",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ratings['movie_id'] = user_ratings['movie'].map(movie_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "834ee770",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_movie_ids = user_ratings['movie_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4dbcb748",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Exception encountered when calling layer 'movie_model_1' (type MovieModel).\n\nOnly integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got 'user_id'\n\nCall arguments received by layer 'movie_model_1' (type MovieModel):\n  • features=tf.Tensor(shape=(4,), dtype=int64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m predicted_movies \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_movie_ids\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Movie-Recommendation-Engine/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn[13], line 49\u001b[0m, in \u001b[0;36mMovieModel.call\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, features: Dict[Text, tf\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m tf\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     48\u001b[0m   \u001b[38;5;66;03m# We pick out the user features and pass them into the user model.\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m   user_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_model(\u001b[43mfeatures\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     50\u001b[0m   \u001b[38;5;66;03m# And pick out the movie features and pass them into the movie model.\u001b[39;00m\n\u001b[1;32m     51\u001b[0m   movie_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmovie_model(features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmovie_title\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mTypeError\u001b[0m: Exception encountered when calling layer 'movie_model_1' (type MovieModel).\n\nOnly integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got 'user_id'\n\nCall arguments received by layer 'movie_model_1' (type MovieModel):\n  • features=tf.Tensor(shape=(4,), dtype=int64)"
     ]
    }
   ],
   "source": [
    "predicted_movies = model(user_movie_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a2244a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tempfile.TemporaryDirectory() as tmp:\n",
    "  path = os.path.join(tmp, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6720b0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_movie(user, top_n=3):\n",
    "    # Create a model that takes in raw query features, and\n",
    "    index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
    "    print(type(index))\n",
    "    # recommends movies out of the entire movies dataset.\n",
    "    index.index_from_dataset(\n",
    "      tf.data.Dataset.zip((movies.batch(100), movies.batch(100).map(model.movie_model)))\n",
    "    )\n",
    "\n",
    "    # Get recommendations.\n",
    "    _, titles = index(tf.constant([str(user)]))\n",
    "    \n",
    "    tf.saved_model.save(index, path)\n",
    "    \n",
    "    print('Top {} recommendations for user {}:\\n'.format(top_n, user))\n",
    "    for i, title in enumerate(titles[0, :top_n].numpy()):\n",
    "        print('{}. {}'.format(i+1, title.decode(\"utf-8\")))\n",
    "\n",
    "def predict_rating(user, movie):\n",
    "    trained_movie_embeddings, trained_user_embeddings, predicted_rating = model({\n",
    "          \"userId\": np.array([str(user)]),\n",
    "          \"original_title\": np.array([movie])\n",
    "      })\n",
    "    print(\"Predicted rating for {}: {}\".format(movie, predicted_rating.numpy()[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bd364eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow_recommenders.layers.factorized_top_k.BruteForce'>\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpba3typxi/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpba3typxi/model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 recommendations for user 123:\n",
      "\n",
      "1. It Happened One Night (1934)\n",
      "2. Secrets & Lies (1996)\n",
      "3. Philadelphia Story, The (1940)\n"
     ]
    }
   ],
   "source": [
    "predict_movie(user=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133cf0bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "497fb314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load it back; can also be done in TensorFlow Serving.\n",
    "loaded = tf.saved_model.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "234d498e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations: [b'Rudy (1993)' b'Client, The (1994)'\n",
      " b'Bridges of Madison County, The (1995)']\n"
     ]
    }
   ],
   "source": [
    "# Pass a user id in, get top predicted movie titles back.\n",
    "scores, titles = loaded([\"42\"])\n",
    "\n",
    "print(f\"Recommendations: {titles[0][:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8804a909",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.saved_model.load.Loader._recreate_base_user_object.<locals>._UserObject at 0x7f76343a9720>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d4cd2d",
   "metadata": {},
   "source": [
    "# this below somewhat worked so worth to investigate further!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9ceda098",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Slicing dataset elements is not supported for rank 0.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[97], line 21\u001b[0m\n\u001b[1;32m     17\u001b[0m movies \u001b[38;5;241m=\u001b[39m movies  \u001b[38;5;66;03m# At least 5 movies\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Recreate the index\u001b[39;00m\n\u001b[1;32m     20\u001b[0m index\u001b[38;5;241m.\u001b[39mindex_from_dataset(\n\u001b[0;32m---> 21\u001b[0m   \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_tensor_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmovies\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mbatch(\u001b[38;5;241m100\u001b[39m)\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m x: (x, loaded_model\u001b[38;5;241m.\u001b[39mmovie_model(x)))\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Generate recommendations for a user (dummy or real user ID)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m user_id \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconstant([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdummy_user\u001b[39m\u001b[38;5;124m\"\u001b[39m])  \u001b[38;5;66;03m# Replace with actual user ID if available\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Movie-Recommendation-Engine/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:825\u001b[0m, in \u001b[0;36mDatasetV2.from_tensor_slices\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops ->\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;66;03m# from_tensor_slices_op -> dataset_ops).\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m from_tensor_slices_op\n\u001b[0;32m--> 825\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfrom_tensor_slices_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_tensor_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Movie-Recommendation-Engine/lib/python3.10/site-packages/tensorflow/python/data/ops/from_tensor_slices_op.py:25\u001b[0m, in \u001b[0;36m_from_tensor_slices\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_from_tensor_slices\u001b[39m(tensors, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 25\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_TensorSliceDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Movie-Recommendation-Engine/lib/python3.10/site-packages/tensorflow/python/data/ops/from_tensor_slices_op.py:35\u001b[0m, in \u001b[0;36m_TensorSliceDataset.__init__\u001b[0;34m(self, element, is_files, name)\u001b[0m\n\u001b[1;32m     33\u001b[0m element \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mnormalize_element(element)\n\u001b[1;32m     34\u001b[0m batched_spec \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mtype_spec_from_value(element)\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensors \u001b[38;5;241m=\u001b[39m \u001b[43mstructure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_batched_tensor_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatched_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensors:\n\u001b[1;32m     37\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid `element`. `element` should not be empty.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Movie-Recommendation-Engine/lib/python3.10/site-packages/tensorflow/python/data/util/structure.py:386\u001b[0m, in \u001b[0;36mto_batched_tensor_list\u001b[0;34m(element_spec, element)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a tensor list representation of the element.\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \n\u001b[1;32m    368\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;124;03m    in any of their substructures.\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-long-lambda\u001b[39;00m\n\u001b[0;32m--> 386\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_to_tensor_list_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomponent\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mspec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_to_batched_tensor_list\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcomponent\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melement_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melement\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Movie-Recommendation-Engine/lib/python3.10/site-packages/tensorflow/python/data/util/structure.py:361\u001b[0m, in \u001b[0;36m_to_tensor_list_helper\u001b[0;34m(encode_fn, element_spec, element)\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    356\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValue \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcomponent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not convertible to a tensor with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    357\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    358\u001b[0m       )\n\u001b[1;32m    359\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m encode_fn(state, spec, component)\n\u001b[0;32m--> 361\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunctools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreduce_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43melement_spec\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43melement\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Movie-Recommendation-Engine/lib/python3.10/site-packages/tensorflow/python/data/util/structure.py:359\u001b[0m, in \u001b[0;36m_to_tensor_list_helper.<locals>.reduce_fn\u001b[0;34m(state, value)\u001b[0m\n\u001b[1;32m    354\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m component\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mis_compatible_with(spec\u001b[38;5;241m.\u001b[39mshape):\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    356\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValue \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcomponent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not convertible to a tensor with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    357\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    358\u001b[0m     )\n\u001b[0;32m--> 359\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mencode_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomponent\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Movie-Recommendation-Engine/lib/python3.10/site-packages/tensorflow/python/data/util/structure.py:387\u001b[0m, in \u001b[0;36mto_batched_tensor_list.<locals>.<lambda>\u001b[0;34m(state, spec, component)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a tensor list representation of the element.\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \n\u001b[1;32m    368\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;124;03m    in any of their substructures.\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-long-lambda\u001b[39;00m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _to_tensor_list_helper(\n\u001b[0;32m--> 387\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m state, spec, component: state \u001b[38;5;241m+\u001b[39m \u001b[43mspec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_to_batched_tensor_list\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcomponent\u001b[49m\u001b[43m)\u001b[49m, element_spec, element)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Movie-Recommendation-Engine/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:4678\u001b[0m, in \u001b[0;36mDatasetSpec._to_batched_tensor_list\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4676\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_batched_tensor_list\u001b[39m(\u001b[38;5;28mself\u001b[39m, value):\n\u001b[1;32m   4677\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_shape\u001b[38;5;241m.\u001b[39mndims \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 4678\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSlicing dataset elements is not supported for rank 0.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4679\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_to_tensor_list(value)\n",
      "\u001b[0;31mValueError\u001b[0m: Slicing dataset elements is not supported for rank 0."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "# Example user ratings\n",
    "user_ratings = pd.DataFrame({\n",
    "    'movie': ['Movie 1', 'Movie 2', 'Movie 3', 'Movie 4'],\n",
    "    'rating': [5, 4, 5, 2]\n",
    "})\n",
    "\n",
    "# Load the saved model (the user and movie models)\n",
    "loaded_model = model\n",
    "\n",
    "# Recreate the BruteForce index using the loaded user and movie models\n",
    "index = tfrs.layers.factorized_top_k.BruteForce(loaded_model.user_model)\n",
    "\n",
    "# Replace with your full movie dataset (ensure it contains enough movies)\n",
    "movies = movies  # At least 5 movies\n",
    "\n",
    "# Recreate the index\n",
    "index.index_from_dataset(\n",
    "  tf.data.Dataset.from_tensor_slices(movies).batch(100).map(lambda x: (x, loaded_model.movie_model(x)))\n",
    ")\n",
    "\n",
    "# Generate recommendations for a user (dummy or real user ID)\n",
    "user_id = tf.constant([\"dummy_user\"])  # Replace with actual user ID if available\n",
    "\n",
    "# Adjust the number of recommendations to match the number of available movies\n",
    "_, recommended_movie_titles = index(user_id, k=5)  # Adjust k to the available number of movies\n",
    "\n",
    "# Output the recommended movie titles\n",
    "print(\"Recommended movies:\", recommended_movie_titles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f697272a",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "cannot compute Pack as input #1(zero-based) was expected to be a float tensor but is a string tensor [Op:Pack] name: 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m user_profile_embedding\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Create a user profile based on rated movies\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m user_profile \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_user_profile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_ratings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmovie\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_ratings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrating\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Output the user profile embedding\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser profile embedding:\u001b[39m\u001b[38;5;124m\"\u001b[39m, user_profile)\n",
      "Cell \u001b[0;32mIn[75], line 26\u001b[0m, in \u001b[0;36mcreate_user_profile\u001b[0;34m(model, movie_titles, ratings)\u001b[0m\n\u001b[1;32m     23\u001b[0m     weighted_embeddings\u001b[38;5;241m.\u001b[39mappend(weighted_embedding)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Combine weighted embeddings (average them for simplicity)\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m user_profile_embedding \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce_mean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweighted_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m user_profile_embedding\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Movie-Recommendation-Engine/lib/python3.10/site-packages/tensorflow/python/ops/weak_tensor_ops.py:88\u001b[0m, in \u001b[0;36mweak_tensor_unary_op_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     87\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     90\u001b[0m   bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Movie-Recommendation-Engine/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Movie-Recommendation-Engine/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:5883\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5881\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m   5882\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 5883\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: cannot compute Pack as input #1(zero-based) was expected to be a float tensor but is a string tensor [Op:Pack] name: 0"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Example user ratings\n",
    "user_ratings = pd.DataFrame({\n",
    "    'movie': ['Movie 1', 'Movie 2', 'Movie 3', 'Movie 4'],\n",
    "    'rating': [5, 4, 5, 2]\n",
    "})\n",
    "\n",
    "# Load your trained TFRS model\n",
    "model = loaded\n",
    "\n",
    "# Define a function to create a weighted user profile\n",
    "def create_user_profile(model, movie_titles, ratings):\n",
    "    weighted_embeddings = []\n",
    "    \n",
    "    # Loop through each movie and rating\n",
    "    for movie_title, rating in zip(movie_titles, ratings):\n",
    "        # Get the movie's embedding by passing the movie title through the model\n",
    "        movie_embedding = model(tf.constant([movie_title]))  # Adjust to match your model's interface\n",
    "        \n",
    "        # Weight the embedding by the rating\n",
    "        weighted_embedding = movie_embedding * rating\n",
    "        weighted_embeddings.append(weighted_embedding)\n",
    "    \n",
    "    # Combine weighted embeddings (average them for simplicity)\n",
    "    user_profile_embedding = tf.reduce_mean(weighted_embeddings, axis=0)\n",
    "    \n",
    "    return user_profile_embedding\n",
    "\n",
    "# Create a user profile based on rated movies\n",
    "user_profile = create_user_profile(model, user_ratings['movie'].values, user_ratings['rating'].values)\n",
    "\n",
    "# Output the user profile embedding\n",
    "print(\"User profile embedding:\", user_profile)\n",
    "\n",
    "# Now use this user profile to get recommendations\n",
    "# You can pass this user profile to your model to get recommendations (depends on the structure of your model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a005804c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended movies: (<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
      "array([[0.17887518, 0.15814601, 0.15369767, 0.13824794, 0.13824794,\n",
      "        0.13281173, 0.12472201, 0.12226161, 0.12219059, 0.11474586]],\n",
      "      dtype=float32)>, <tf.Tensor: shape=(1, 10), dtype=string, numpy=\n",
      "array([[b'Bride of Frankenstein (1935)', b'Howling, The (1981)',\n",
      "        b'American Werewolf in London, An (1981)',\n",
      "        b'Body Snatchers (1993)', b'Body Snatchers (1993)',\n",
      "        b'Tales From the Crypt Presents: Demon Knight (1995)',\n",
      "        b'Carrie (1976)', b'Mark of Zorro, The (1940)',\n",
      "        b'Omen, The (1976)',\n",
      "        b'Nosferatu (Nosferatu, eine Symphonie des Grauens) (1922)']],\n",
      "      dtype=object)>)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load your trained TFRS model\n",
    "model = loaded\n",
    "\n",
    "# Create input features (user_id only)\n",
    "input_features = tf.constant([\"dummy_user\"])  # Dummy user ID for a new user\n",
    "\n",
    "# Pass the input features into the model to get recommendations\n",
    "predicted_movies = model(input_features)\n",
    "\n",
    "# Output the recommendations\n",
    "print(\"Recommended movies:\", predicted_movies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1210ecea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended movies similar to 'Movie 1': (<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
      "array([[0.17887518, 0.15814601, 0.15369767, 0.13824794, 0.13824794,\n",
      "        0.13281173, 0.12472201, 0.12226161, 0.12219059, 0.11474586]],\n",
      "      dtype=float32)>, <tf.Tensor: shape=(1, 10), dtype=string, numpy=\n",
      "array([[b'Bride of Frankenstein (1935)', b'Howling, The (1981)',\n",
      "        b'American Werewolf in London, An (1981)',\n",
      "        b'Body Snatchers (1993)', b'Body Snatchers (1993)',\n",
      "        b'Tales From the Crypt Presents: Demon Knight (1995)',\n",
      "        b'Carrie (1976)', b'Mark of Zorro, The (1940)',\n",
      "        b'Omen, The (1976)',\n",
      "        b'Nosferatu (Nosferatu, eine Symphonie des Grauens) (1922)']],\n",
      "      dtype=object)>)\n"
     ]
    }
   ],
   "source": [
    "input_features = tf.constant([\"Movie 1\"])  # Example of passing a movie title\n",
    "predicted_movies = model(input_features)\n",
    "print(\"Recommended movies similar to 'Movie 1':\", predicted_movies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99138f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1175ba8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67df37a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c53ea49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1' # Set deterministic ops for TensorFlow"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
