{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7801a195",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622aabcc",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3026dc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ff2c7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "153294b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 17:25:42.036193: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-06 17:25:42.062857: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-06 17:25:42.062888: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-06 17:25:42.063747: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-06 17:25:42.069155: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-06 17:25:42.069922: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-06 17:25:42.993334: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/marcel/.pyenv/versions/3.10.6/envs/Movie-Recommendation-Engine/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_recommenders as tfrs\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0127d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dfacb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8469e27b",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85378c1",
   "metadata": {},
   "source": [
    "Documentation for datasets: https://www.tensorflow.org/datasets/catalog/movielens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a596e13a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 17:25:45.021320: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-09-06 17:25:45.021596: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# Ratings data.\n",
    "ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\")\n",
    "# Features of all the available movies.\n",
    "movies = tfds.load(\"movielens/100k-movies\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "005ae197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.prefetch_op._PrefetchDataset"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb18918e",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Transform tfds to dataframe for exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55c9859",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ratings_df = tfds.as_dataframe(ratings)\n",
    "movies_df = tfds.as_dataframe(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81fb601",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ratings_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d1cdbe",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "movies_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc91b9ef",
   "metadata": {},
   "source": [
    "### Create mapping of relevant features from the tfds for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "445b4d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings.map(lambda x: {\n",
    "    \"movie_title\": x[\"movie_title\"],\n",
    "    \"user_id\": x[\"user_id\"],\n",
    "    \"user_rating\": float(x[\"user_rating\"])\n",
    "})\n",
    "movies = movies.map(lambda x: x[\"movie_title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2dc04406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.map_op._MapDataset"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae07695a",
   "metadata": {},
   "source": [
    "# The model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abea8b7a",
   "metadata": {},
   "source": [
    "## Shuffle, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b3808b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Data: 100000\n"
     ]
    }
   ],
   "source": [
    "print('Total Data: {}'.format(len(ratings)))\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = ratings.take(80_000)\n",
    "test = ratings.skip(80_000).take(20_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e59bc5",
   "metadata": {},
   "source": [
    "## Create batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3764e244",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_titles = movies.batch(1_024)\n",
    "user_ids = ratings.batch(1_024).map(lambda x: x[\"user_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b7bf1f",
   "metadata": {},
   "source": [
    "## Get unique user_ids and movie_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba00614",
   "metadata": {},
   "source": [
    "... to later convert each user_id and movie_title to a unique integer index for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3eaa4b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_movie_titles = np.unique(np.concatenate(list(movie_titles)))\n",
    "unique_user_ids = np.unique(np.concatenate(list(user_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8080a791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Movies: 1664\n",
      "Unique users: 943\n"
     ]
    }
   ],
   "source": [
    "print('Unique Movies: {}'.format(len(unique_movie_titles)))\n",
    "print('Unique users: {}'.format(len(unique_user_ids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f765cfb0",
   "metadata": {},
   "source": [
    "## The model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8c5148",
   "metadata": {},
   "source": [
    "### Basic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6097ca96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieModel(tfrs.models.Model):\n",
    "\n",
    "  def __init__(self, rating_weight: float, retrieval_weight: float) -> None:\n",
    "    # We take the loss weights in the constructor: this allows us to instantiate\n",
    "    # several model objects with different loss weights.\n",
    "\n",
    "    super().__init__()\n",
    "\n",
    "    embedding_dimension = 64\n",
    "\n",
    "    # User and movie models.\n",
    "    self.movie_model: tf.keras.layers.Layer = tf.keras.Sequential([\n",
    "      tf.keras.layers.StringLookup(\n",
    "        vocabulary=unique_movie_titles, mask_token=None),\n",
    "      tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding_dimension)\n",
    "    ])\n",
    "    self.user_model: tf.keras.layers.Layer = tf.keras.Sequential([\n",
    "      tf.keras.layers.StringLookup(\n",
    "        vocabulary=unique_user_ids, mask_token=None),\n",
    "      tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "    ])\n",
    "\n",
    "    # A small model to take in user and movie embeddings and predict ratings.\n",
    "    # We can make this as complicated as we want as long as we output a scalar\n",
    "    # as our prediction.\n",
    "    self.rating_model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(1),\n",
    "    ])\n",
    "\n",
    "    # The tasks.\n",
    "    self.rating_task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
    "        loss=tf.keras.losses.MeanSquaredError(),\n",
    "        metrics=[tf.keras.metrics.RootMeanSquaredError()],\n",
    "    )\n",
    "    self.retrieval_task: tf.keras.layers.Layer = tfrs.tasks.Retrieval(\n",
    "        metrics=tfrs.metrics.FactorizedTopK(\n",
    "            candidates=movies.batch(128).map(self.movie_model)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # The loss weights.\n",
    "    self.rating_weight = rating_weight\n",
    "    self.retrieval_weight = retrieval_weight\n",
    "\n",
    "  def call(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\n",
    "    # We pick out the user features and pass them into the user model.\n",
    "    user_embeddings = self.user_model(features[\"user_id\"])\n",
    "    # And pick out the movie features and pass them into the movie model.\n",
    "    movie_embeddings = self.movie_model(features[\"movie_title\"])\n",
    "    \n",
    "    return (\n",
    "        user_embeddings,\n",
    "        movie_embeddings,\n",
    "        # We apply the multi-layered rating model to a concatentation of\n",
    "        # user and movie embeddings.\n",
    "        self.rating_model(\n",
    "            tf.concat([user_embeddings, movie_embeddings], axis=1)\n",
    "        ),\n",
    "    )\n",
    "\n",
    "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "\n",
    "    ratings = features.pop(\"user_rating\")\n",
    "\n",
    "    user_embeddings, movie_embeddings, rating_predictions = self(features)\n",
    "\n",
    "    # We compute the loss for each task.\n",
    "    rating_loss = self.rating_task(\n",
    "        labels=ratings,\n",
    "        predictions=rating_predictions,\n",
    "    )\n",
    "    retrieval_loss = self.retrieval_task(user_embeddings, movie_embeddings)\n",
    "\n",
    "    # And combine them using the loss weights.\n",
    "    return (self.rating_weight * rating_loss\n",
    "            + self.retrieval_weight * retrieval_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09107fb",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Model: Try to get it deterministic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d75892",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class MovieModel(tfrs.models.Model):\n",
    "\n",
    "    def __init__(self, movies, unique_movie_titles, unique_user_ids, rating_weight: float, retrieval_weight: float, seed=42) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        embedding_dimension = 64\n",
    "\n",
    "        # Seeded initializers for embeddings to ensure determinism\n",
    "        embedding_initializer = tf.keras.initializers.GlorotUniform(seed=seed)\n",
    "\n",
    "        # User and movie models.\n",
    "        self.movie_model: tf.keras.layers.Layer = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(\n",
    "                vocabulary=unique_movie_titles, mask_token=None),\n",
    "            tf.keras.layers.Embedding(\n",
    "                len(unique_movie_titles) + 1,\n",
    "                embedding_dimension,\n",
    "                embeddings_initializer=embedding_initializer  # Seeded initializer\n",
    "            )\n",
    "        ])\n",
    "        self.user_model: tf.keras.layers.Layer = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(\n",
    "                vocabulary=unique_user_ids, mask_token=None),\n",
    "            tf.keras.layers.Embedding(\n",
    "                len(unique_user_ids) + 1,\n",
    "                embedding_dimension,\n",
    "                embeddings_initializer=embedding_initializer  # Seeded initializer\n",
    "            )\n",
    "        ])\n",
    "\n",
    "        # A small model to take in user and movie embeddings and predict ratings.\n",
    "        self.rating_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(256, activation=\"relu\", kernel_initializer=tf.keras.initializers.GlorotUniform(seed=seed)),\n",
    "            tf.keras.layers.Dense(128, activation=\"relu\", kernel_initializer=tf.keras.initializers.GlorotUniform(seed=seed)),\n",
    "            tf.keras.layers.Dense(1, kernel_initializer=tf.keras.initializers.GlorotUniform(seed=seed)),\n",
    "        ])\n",
    "\n",
    "        # The tasks.\n",
    "        self.rating_task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
    "            loss=tf.keras.losses.MeanSquaredError(),\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError()],\n",
    "        )\n",
    "        self.retrieval_task: tf.keras.layers.Layer = tfrs.tasks.Retrieval(\n",
    "            metrics=tfrs.metrics.FactorizedTopK(\n",
    "                candidates=movies.batch(128).map(self.movie_model)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # The loss weights.\n",
    "        self.rating_weight = rating_weight\n",
    "        self.retrieval_weight = retrieval_weight\n",
    "\n",
    "    def call(self, features: dict) -> tf.Tensor:\n",
    "        # Extract user and movie features and pass them to the respective models.\n",
    "        user_embeddings = self.user_model(features[\"user_id\"])\n",
    "        movie_embeddings = self.movie_model(features[\"movie_title\"])\n",
    "\n",
    "        # Concatenate user and movie embeddings and pass through the rating model.\n",
    "        return (\n",
    "            user_embeddings,\n",
    "            movie_embeddings,\n",
    "            self.rating_model(\n",
    "                tf.concat([user_embeddings, movie_embeddings], axis=1)\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def compute_loss(self, features: dict, training=False) -> tf.Tensor:\n",
    "        ratings = features.pop(\"user_ratings\")\n",
    "\n",
    "        user_embeddings, movie_embeddings, rating_predictions = self(features)\n",
    "\n",
    "        # Compute loss for both tasks (ranking and retrieval).\n",
    "        rating_loss = self.rating_task(\n",
    "            labels=ratings,\n",
    "            predictions=rating_predictions,\n",
    "        )\n",
    "        retrieval_loss = self.retrieval_task(user_embeddings, movie_embeddings)\n",
    "\n",
    "        # Combine the losses using the specified weights.\n",
    "        return (self.rating_weight * rating_loss\n",
    "                + self.retrieval_weight * retrieval_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc678f50",
   "metadata": {},
   "source": [
    "## Fitting and evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74eb1846",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MovieModel(rating_weight=1.0, retrieval_weight=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bba7e75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8599ef27",
   "metadata": {},
   "source": [
    "## Shuffle, batch and cache the training and evaluation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b10eae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_train = train.batch(1_024).cache()\n",
    "cached_test = test.batch(1_024).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807ab722",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18172b3",
   "metadata": {},
   "source": [
    "def train_model():\n",
    "    history = model.fit(cached_train, epochs=3)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9f51a5",
   "metadata": {},
   "source": [
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0647d9be",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 8s 84ms/step - root_mean_squared_error: 1.2439 - factorized_top_k/top_1_categorical_accuracy: 1.7500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0074 - factorized_top_k/top_10_categorical_accuracy: 0.0186 - factorized_top_k/top_50_categorical_accuracy: 0.1003 - factorized_top_k/top_100_categorical_accuracy: 0.1843 - loss: 6879.2710 - regularization_loss: 0.0000e+00 - total_loss: 6879.2710\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f6b2c1a3ee0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(cached_train, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf823def",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b04011",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd8d69d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow_recommenders.metrics.factorized_top_k.FactorizedTopK object at 0x7f6b2c1a8af0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow_recommenders.metrics.factorized_top_k.FactorizedTopK object at 0x7f6b2c1a8af0>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error saving model: {{function_node __wrapped__DatasetToGraphV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Failed to serialize the input pipeline graph: ResourceGather is stateful. [Op:DatasetToGraphV2] name: \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tempfile\n",
    "\n",
    "def save_model(model):\n",
    "    # Create a temporary directory to save the model\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "\n",
    "    # Save the model in TensorFlow's SavedModel format\n",
    "    try:\n",
    "        model.save(filepath=temp_dir, save_format='tf')\n",
    "        print(f\"Model successfully saved to: {temp_dir}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving model: {e}\")\n",
    "\n",
    "    return temp_dir\n",
    "\n",
    "# Assuming the model is already compiled and trained\n",
    "saved_dir = save_model(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64a134a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f9cd1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 17:29:28.047008: W tensorflow/core/framework/op_kernel.cc:1816] OP_REQUIRES failed at cast_op.cc:122 : UNIMPLEMENTED: Cast int32 to string is not supported\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Exception encountered when calling layer 'sequential_1' (type Sequential).\n\n{{function_node __wrapped__Cast_device_/job:localhost/replica:0/task:0/device:CPU:0}} Cast int32 to string is not supported [Op:Cast] name: \n\nCall arguments received by layer 'sequential_1' (type Sequential):\n  • inputs=tf.Tensor(shape=(1,), dtype=int32)\n  • training=None\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m temp_dir\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Assuming the model is already compiled and trained\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m saved_dir \u001b[38;5;241m=\u001b[39m \u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[22], line 11\u001b[0m, in \u001b[0;36msave_model\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      9\u001b[0m dummy_user_input \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconstant([\u001b[38;5;241m0\u001b[39m])  \u001b[38;5;66;03m# Replace with suitable input\u001b[39;00m\n\u001b[1;32m     10\u001b[0m dummy_movie_input \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconstant([\u001b[38;5;241m0\u001b[39m])  \u001b[38;5;66;03m# Replace with suitable input\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdummy_user_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmovie_title\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdummy_movie_input\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Save the model in TensorFlow's SavedModel format\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Movie-Recommendation-Engine/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn[14], line 49\u001b[0m, in \u001b[0;36mMovieModel.call\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, features: Dict[Text, tf\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m tf\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     48\u001b[0m   \u001b[38;5;66;03m# We pick out the user features and pass them into the user model.\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m   user_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m   \u001b[38;5;66;03m# And pick out the movie features and pass them into the movie model.\u001b[39;00m\n\u001b[1;32m     51\u001b[0m   movie_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmovie_model(features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmovie_title\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mUnimplementedError\u001b[0m: Exception encountered when calling layer 'sequential_1' (type Sequential).\n\n{{function_node __wrapped__Cast_device_/job:localhost/replica:0/task:0/device:CPU:0}} Cast int32 to string is not supported [Op:Cast] name: \n\nCall arguments received by layer 'sequential_1' (type Sequential):\n  • inputs=tf.Tensor(shape=(1,), dtype=int32)\n  • training=None\n  • mask=None"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tempfile\n",
    "\n",
    "def save_model(model):\n",
    "    # Create a temporary directory to save the model\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "\n",
    "    # Ensure the model is built by running a forward pass\n",
    "    dummy_user_input = tf.constant([0])  # Replace with suitable input\n",
    "    dummy_movie_input = tf.constant([0])  # Replace with suitable input\n",
    "    _ = model({\"user_id\": dummy_user_input, \"movie_title\": dummy_movie_input})\n",
    "\n",
    "    # Save the model in TensorFlow's SavedModel format\n",
    "    try:\n",
    "        model.save(filepath=temp_dir, save_format='tf', include_optimizer=False)\n",
    "        print(f\"Model successfully saved to: {temp_dir}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving model: {e}\")\n",
    "\n",
    "    return temp_dir\n",
    "\n",
    "# Assuming the model is already compiled and trained\n",
    "saved_dir = save_model(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba5fe8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0023df72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90f7d94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8646cbed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e711fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a93db7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model():\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    tf.keras.models.save_model(model=model, filepath=temp_dir)\n",
    "    return temp_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b725ef52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow_recommenders.metrics.factorized_top_k.FactorizedTopK object at 0x7f6b2c1a8af0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow_recommenders.metrics.factorized_top_k.FactorizedTopK object at 0x7f6b2c1a8af0>, because it is not built.\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "{{function_node __wrapped__DatasetToGraphV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Failed to serialize the input pipeline graph: ResourceGather is stateful. [Op:DatasetToGraphV2] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m, in \u001b[0;36msave_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_model\u001b[39m():\n\u001b[1;32m      2\u001b[0m     temp_dir \u001b[38;5;241m=\u001b[39m tempfile\u001b[38;5;241m.\u001b[39mmkdtemp()\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemp_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m temp_dir\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Movie-Recommendation-Engine/lib/python3.10/site-packages/keras/src/saving/saving_api.py:167\u001b[0m, in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, save_format, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m     saving_lib\u001b[38;5;241m.\u001b[39msave_model(model, filepath)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# Legacy case\u001b[39;00m\n\u001b[0;32m--> 167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlegacy_sm_saving_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Movie-Recommendation-Engine/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Movie-Recommendation-Engine/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:5883\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5881\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m   5882\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 5883\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: {{function_node __wrapped__DatasetToGraphV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Failed to serialize the input pipeline graph: ResourceGather is stateful. [Op:DatasetToGraphV2] name: "
     ]
    }
   ],
   "source": [
    "save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eb8b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7410939",
   "metadata": {},
   "source": [
    "## Evaluate the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbf8a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = model.evaluate(cached_test, return_dict=True)\n",
    "\n",
    "print(f\"\\nRetrieval top-100 accuracy: {metrics['factorized_top_k/top_100_categorical_accuracy']:.3f}\")\n",
    "print(f\"Ranking RMSE: {metrics['root_mean_squared_error']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4012e2",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc63c710",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import shutil\n",
    "\n",
    "# Predict movie recommendations\n",
    "def predict_movie(user, top_n=3):\n",
    "    # Create a persistent temporary directory\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "\n",
    "    # Create a model that takes in raw query features\n",
    "    index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
    "\n",
    "    # Index the movies dataset\n",
    "    index.index_from_dataset(\n",
    "        tf.data.Dataset.zip((movies.batch(100), movies.batch(100).map(model.movie_model)))\n",
    "    )\n",
    "\n",
    "    # Get recommendations for the user\n",
    "    scores, titles = index(tf.constant([str(user)]))\n",
    "\n",
    "    # Save the model to the temporary directory\n",
    "    tf.keras.models.save_model(model=index, filepath=temp_dir, overwrite=True)\n",
    "    \n",
    "\n",
    "    print(f\"Model saved to temporary directory: {temp_dir}\")\n",
    "\n",
    "    print(f'Top {top_n} recommendations for user {user}:\\n')\n",
    "    for i, title in enumerate(titles[0, :top_n].numpy()):\n",
    "        print(f'{i+1}. {title.decode(\"utf-8\")}')\n",
    "\n",
    "    return temp_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efe8296",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68775d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc0cf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "# Load the trained model (assuming you have saved and loaded your model already)\n",
    "model = tf.keras.models.load_model(temp_dir)\n",
    "\n",
    "# Create an index from the movie dataset\n",
    "# Assume `movies_dataset` is a dataset with your movie features (movie titles, embeddings, etc.)\n",
    "movies = movies_dataset.map(lambda x: x[\"movie_title\"])\n",
    "\n",
    "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
    "index.index(movies.batch(100).map(model.movie_model), movies)\n",
    "\n",
    "# Define the new user’s features (the features that were used in the model training)\n",
    "new_user_features = {\n",
    "    # Example: Add relevant features for the new user if applicable\n",
    "    'user_id': 'new_user_id',\n",
    "}\n",
    "\n",
    "# Use the user model to embed the new user\n",
    "new_user_embedding = model.user_model(new_user_features)\n",
    "\n",
    "# Get recommendations for the new user\n",
    "_, titles = index(tf.constant([new_user_embedding]))\n",
    "\n",
    "print(f\"Recommendations for new user: {titles.numpy()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c509f42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aafbea8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7802f41d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd6031a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_movie(13, top_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866760eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ratings = pd.DataFrame({\n",
    "    'movie': ['Movie 1', 'Movie 2', 'Movie 3', 'Movie 4'],\n",
    "    'rating': [5, 4, 5, 2]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d096cfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_to_id = {\n",
    "    'Movie 1': 1,\n",
    "    'Movie 2': 2,\n",
    "    'Movie 3': 3,\n",
    "    'Movie 4': 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7350b993",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ratings['movie_id'] = user_ratings['movie'].map(movie_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834ee770",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_movie_ids = user_ratings['movie_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbcb748",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predicted_movies = model(user_movie_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2244a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tempfile.TemporaryDirectory() as tmp:\n",
    "  path = os.path.join(tmp, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6720b0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def predict_rating(user, movie):\n",
    "    trained_movie_embeddings, trained_user_embeddings, predicted_rating = model({\n",
    "          \"userId\": np.array([str(user)]),\n",
    "          \"original_title\": np.array([movie])\n",
    "      })\n",
    "    print(\"Predicted rating for {}: {}\".format(movie, predicted_rating.numpy()[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd364eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_movie(user=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133cf0bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497fb314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load it back; can also be done in TensorFlow Serving.\n",
    "loaded = tf.saved_model.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234d498e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass a user id in, get top predicted movie titles back.\n",
    "scores, titles = loaded([\"42\"])\n",
    "\n",
    "print(f\"Recommendations: {titles[0][:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8804a909",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d4cd2d",
   "metadata": {},
   "source": [
    "# this below somewhat worked so worth to investigate further!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ceda098",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "# Example user ratings\n",
    "user_ratings = pd.DataFrame({\n",
    "    'movie': ['Movie 1', 'Movie 2', 'Movie 3', 'Movie 4'],\n",
    "    'rating': [5, 4, 5, 2]\n",
    "})\n",
    "\n",
    "# Load the saved model (the user and movie models)\n",
    "loaded_model = model\n",
    "\n",
    "# Recreate the BruteForce index using the loaded user and movie models\n",
    "index = tfrs.layers.factorized_top_k.BruteForce(loaded_model.user_model)\n",
    "\n",
    "# Replace with your full movie dataset (ensure it contains enough movies)\n",
    "movies = movies  # At least 5 movies\n",
    "\n",
    "# Recreate the index\n",
    "index.index_from_dataset(\n",
    "  tf.data.Dataset.from_tensor_slices(movies).batch(100).map(lambda x: (x, loaded_model.movie_model(x)))\n",
    ")\n",
    "\n",
    "# Generate recommendations for a user (dummy or real user ID)\n",
    "user_id = tf.constant([\"dummy_user\"])  # Replace with actual user ID if available\n",
    "\n",
    "# Adjust the number of recommendations to match the number of available movies\n",
    "_, recommended_movie_titles = index(user_id, k=5)  # Adjust k to the available number of movies\n",
    "\n",
    "# Output the recommended movie titles\n",
    "print(\"Recommended movies:\", recommended_movie_titles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f697272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Example user ratings\n",
    "user_ratings = pd.DataFrame({\n",
    "    'movie': ['Movie 1', 'Movie 2', 'Movie 3', 'Movie 4'],\n",
    "    'rating': [5, 4, 5, 2]\n",
    "})\n",
    "\n",
    "# Load your trained TFRS model\n",
    "model = loaded\n",
    "\n",
    "# Define a function to create a weighted user profile\n",
    "def create_user_profile(model, movie_titles, ratings):\n",
    "    weighted_embeddings = []\n",
    "    \n",
    "    # Loop through each movie and rating\n",
    "    for movie_title, rating in zip(movie_titles, ratings):\n",
    "        # Get the movie's embedding by passing the movie title through the model\n",
    "        movie_embedding = model(tf.constant([movie_title]))  # Adjust to match your model's interface\n",
    "        \n",
    "        # Weight the embedding by the rating\n",
    "        weighted_embedding = movie_embedding * rating\n",
    "        weighted_embeddings.append(weighted_embedding)\n",
    "    \n",
    "    # Combine weighted embeddings (average them for simplicity)\n",
    "    user_profile_embedding = tf.reduce_mean(weighted_embeddings, axis=0)\n",
    "    \n",
    "    return user_profile_embedding\n",
    "\n",
    "# Create a user profile based on rated movies\n",
    "user_profile = create_user_profile(model, user_ratings['movie'].values, user_ratings['rating'].values)\n",
    "\n",
    "# Output the user profile embedding\n",
    "print(\"User profile embedding:\", user_profile)\n",
    "\n",
    "# Now use this user profile to get recommendations\n",
    "# You can pass this user profile to your model to get recommendations (depends on the structure of your model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a005804c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load your trained TFRS model\n",
    "model = loaded\n",
    "\n",
    "# Create input features (user_id only)\n",
    "input_features = tf.constant([\"dummy_user\"])  # Dummy user ID for a new user\n",
    "\n",
    "# Pass the input features into the model to get recommendations\n",
    "predicted_movies = model(input_features)\n",
    "\n",
    "# Output the recommendations\n",
    "print(\"Recommended movies:\", predicted_movies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1210ecea",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features = tf.constant([\"Movie 1\"])  # Example of passing a movie title\n",
    "predicted_movies = model(input_features)\n",
    "print(\"Recommended movies similar to 'Movie 1':\", predicted_movies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99138f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1175ba8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67df37a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c53ea49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1' # Set deterministic ops for TensorFlow"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
