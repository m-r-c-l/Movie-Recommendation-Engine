{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7801a195",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622aabcc",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3026dc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ff2c7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "153294b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 16:22:03.212833: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-06 16:22:03.538601: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-06 16:22:03.538687: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-06 16:22:03.604168: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-06 16:22:03.732989: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-06 16:22:03.735102: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-06 16:22:05.171413: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/marcel/.pyenv/versions/3.10.6/envs/Movie-Recommendation-Engine/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_recommenders as tfrs\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0127d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dfacb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8469e27b",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85378c1",
   "metadata": {},
   "source": [
    "Documentation for datasets: https://www.tensorflow.org/datasets/catalog/movielens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a596e13a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 16:22:08.220148: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-09-06 16:22:08.220507: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# Ratings data.\n",
    "ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\")\n",
    "# Features of all the available movies.\n",
    "movies = tfds.load(\"movielens/100k-movies\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005ae197",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb18918e",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Transform tfds to dataframe for exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55c9859",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ratings_df = tfds.as_dataframe(ratings)\n",
    "movies_df = tfds.as_dataframe(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81fb601",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ratings_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d1cdbe",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "movies_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc91b9ef",
   "metadata": {},
   "source": [
    "### Create mapping of relevant features from the tfds for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "445b4d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings.map(lambda x: {\n",
    "    \"movie_title\": x[\"movie_title\"],\n",
    "    \"user_id\": x[\"user_id\"],\n",
    "    \"user_rating\": float(x[\"user_rating\"])\n",
    "})\n",
    "movies = movies.map(lambda x: x[\"movie_title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc04406",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae07695a",
   "metadata": {},
   "source": [
    "# The model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abea8b7a",
   "metadata": {},
   "source": [
    "## Shuffle, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b3808b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Data: 100000\n"
     ]
    }
   ],
   "source": [
    "print('Total Data: {}'.format(len(ratings)))\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = ratings.take(80_000)\n",
    "test = ratings.skip(80_000).take(20_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e59bc5",
   "metadata": {},
   "source": [
    "## Create batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3764e244",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_titles = movies.batch(1_024)\n",
    "user_ids = ratings.batch(1_024).map(lambda x: x[\"user_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b7bf1f",
   "metadata": {},
   "source": [
    "## Get unique user_ids and movie_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba00614",
   "metadata": {},
   "source": [
    "... to later convert each user_id and movie_title to a unique integer index for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3eaa4b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_movie_titles = np.unique(np.concatenate(list(movie_titles)))\n",
    "unique_user_ids = np.unique(np.concatenate(list(user_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8080a791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Movies: 1664\n",
      "Unique users: 943\n"
     ]
    }
   ],
   "source": [
    "print('Unique Movies: {}'.format(len(unique_movie_titles)))\n",
    "print('Unique users: {}'.format(len(unique_user_ids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f765cfb0",
   "metadata": {},
   "source": [
    "## The model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8c5148",
   "metadata": {},
   "source": [
    "### Basic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6097ca96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieModel(tfrs.models.Model):\n",
    "\n",
    "  def __init__(self, rating_weight: float, retrieval_weight: float) -> None:\n",
    "    # We take the loss weights in the constructor: this allows us to instantiate\n",
    "    # several model objects with different loss weights.\n",
    "\n",
    "    super().__init__()\n",
    "\n",
    "    embedding_dimension = 64\n",
    "\n",
    "    # User and movie models.\n",
    "    self.movie_model: tf.keras.layers.Layer = tf.keras.Sequential([\n",
    "      tf.keras.layers.StringLookup(\n",
    "        vocabulary=unique_movie_titles, mask_token=None),\n",
    "      tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding_dimension)\n",
    "    ])\n",
    "    self.user_model: tf.keras.layers.Layer = tf.keras.Sequential([\n",
    "      tf.keras.layers.StringLookup(\n",
    "        vocabulary=unique_user_ids, mask_token=None),\n",
    "      tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "    ])\n",
    "\n",
    "    # A small model to take in user and movie embeddings and predict ratings.\n",
    "    # We can make this as complicated as we want as long as we output a scalar\n",
    "    # as our prediction.\n",
    "    self.rating_model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(1),\n",
    "    ])\n",
    "\n",
    "    # The tasks.\n",
    "    self.rating_task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
    "        loss=tf.keras.losses.MeanSquaredError(),\n",
    "        metrics=[tf.keras.metrics.RootMeanSquaredError()],\n",
    "    )\n",
    "    self.retrieval_task: tf.keras.layers.Layer = tfrs.tasks.Retrieval(\n",
    "        metrics=tfrs.metrics.FactorizedTopK(\n",
    "            candidates=movies.batch(128).map(self.movie_model)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # The loss weights.\n",
    "    self.rating_weight = rating_weight\n",
    "    self.retrieval_weight = retrieval_weight\n",
    "\n",
    "  def call(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\n",
    "    # We pick out the user features and pass them into the user model.\n",
    "    user_embeddings = self.user_model(features[\"user_id\"])\n",
    "    # And pick out the movie features and pass them into the movie model.\n",
    "    movie_embeddings = self.movie_model(features[\"movie_title\"])\n",
    "    \n",
    "    return (\n",
    "        user_embeddings,\n",
    "        movie_embeddings,\n",
    "        # We apply the multi-layered rating model to a concatentation of\n",
    "        # user and movie embeddings.\n",
    "        self.rating_model(\n",
    "            tf.concat([user_embeddings, movie_embeddings], axis=1)\n",
    "        ),\n",
    "    )\n",
    "\n",
    "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "\n",
    "    ratings = features.pop(\"user_rating\")\n",
    "\n",
    "    user_embeddings, movie_embeddings, rating_predictions = self(features)\n",
    "\n",
    "    # We compute the loss for each task.\n",
    "    rating_loss = self.rating_task(\n",
    "        labels=ratings,\n",
    "        predictions=rating_predictions,\n",
    "    )\n",
    "    retrieval_loss = self.retrieval_task(user_embeddings, movie_embeddings)\n",
    "\n",
    "    # And combine them using the loss weights.\n",
    "    return (self.rating_weight * rating_loss\n",
    "            + self.retrieval_weight * retrieval_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09107fb",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Model: Try to get it deterministic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d75892",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class MovieModel(tfrs.models.Model):\n",
    "\n",
    "    def __init__(self, movies, unique_movie_titles, unique_user_ids, rating_weight: float, retrieval_weight: float, seed=42) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        embedding_dimension = 64\n",
    "\n",
    "        # Seeded initializers for embeddings to ensure determinism\n",
    "        embedding_initializer = tf.keras.initializers.GlorotUniform(seed=seed)\n",
    "\n",
    "        # User and movie models.\n",
    "        self.movie_model: tf.keras.layers.Layer = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(\n",
    "                vocabulary=unique_movie_titles, mask_token=None),\n",
    "            tf.keras.layers.Embedding(\n",
    "                len(unique_movie_titles) + 1,\n",
    "                embedding_dimension,\n",
    "                embeddings_initializer=embedding_initializer  # Seeded initializer\n",
    "            )\n",
    "        ])\n",
    "        self.user_model: tf.keras.layers.Layer = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(\n",
    "                vocabulary=unique_user_ids, mask_token=None),\n",
    "            tf.keras.layers.Embedding(\n",
    "                len(unique_user_ids) + 1,\n",
    "                embedding_dimension,\n",
    "                embeddings_initializer=embedding_initializer  # Seeded initializer\n",
    "            )\n",
    "        ])\n",
    "\n",
    "        # A small model to take in user and movie embeddings and predict ratings.\n",
    "        self.rating_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(256, activation=\"relu\", kernel_initializer=tf.keras.initializers.GlorotUniform(seed=seed)),\n",
    "            tf.keras.layers.Dense(128, activation=\"relu\", kernel_initializer=tf.keras.initializers.GlorotUniform(seed=seed)),\n",
    "            tf.keras.layers.Dense(1, kernel_initializer=tf.keras.initializers.GlorotUniform(seed=seed)),\n",
    "        ])\n",
    "\n",
    "        # The tasks.\n",
    "        self.rating_task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
    "            loss=tf.keras.losses.MeanSquaredError(),\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError()],\n",
    "        )\n",
    "        self.retrieval_task: tf.keras.layers.Layer = tfrs.tasks.Retrieval(\n",
    "            metrics=tfrs.metrics.FactorizedTopK(\n",
    "                candidates=movies.batch(128).map(self.movie_model)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # The loss weights.\n",
    "        self.rating_weight = rating_weight\n",
    "        self.retrieval_weight = retrieval_weight\n",
    "\n",
    "    def call(self, features: dict) -> tf.Tensor:\n",
    "        # Extract user and movie features and pass them to the respective models.\n",
    "        user_embeddings = self.user_model(features[\"user_id\"])\n",
    "        movie_embeddings = self.movie_model(features[\"movie_title\"])\n",
    "\n",
    "        # Concatenate user and movie embeddings and pass through the rating model.\n",
    "        return (\n",
    "            user_embeddings,\n",
    "            movie_embeddings,\n",
    "            self.rating_model(\n",
    "                tf.concat([user_embeddings, movie_embeddings], axis=1)\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def compute_loss(self, features: dict, training=False) -> tf.Tensor:\n",
    "        ratings = features.pop(\"user_ratings\")\n",
    "\n",
    "        user_embeddings, movie_embeddings, rating_predictions = self(features)\n",
    "\n",
    "        # Compute loss for both tasks (ranking and retrieval).\n",
    "        rating_loss = self.rating_task(\n",
    "            labels=ratings,\n",
    "            predictions=rating_predictions,\n",
    "        )\n",
    "        retrieval_loss = self.retrieval_task(user_embeddings, movie_embeddings)\n",
    "\n",
    "        # Combine the losses using the specified weights.\n",
    "        return (self.rating_weight * rating_loss\n",
    "                + self.retrieval_weight * retrieval_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc678f50",
   "metadata": {},
   "source": [
    "## Fitting and evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "74eb1846",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MovieModel(rating_weight=1.0, retrieval_weight=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bba7e75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8599ef27",
   "metadata": {},
   "source": [
    "## Shuffle, batch and cache the training and evaluation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0b10eae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_train = train.batch(1_024).cache()\n",
    "cached_test = test.batch(1_024).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807ab722",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18172b3",
   "metadata": {},
   "source": [
    "def train_model():\n",
    "    history = model.fit(cached_train, epochs=3)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9f51a5",
   "metadata": {},
   "source": [
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0647d9be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 8s 88ms/step - root_mean_squared_error: 1.2351 - factorized_top_k/top_1_categorical_accuracy: 8.7500e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0072 - factorized_top_k/top_10_categorical_accuracy: 0.0180 - factorized_top_k/top_50_categorical_accuracy: 0.0964 - factorized_top_k/top_100_categorical_accuracy: 0.1754 - loss: 6883.7860 - regularization_loss: 0.0000e+00 - total_loss: 6883.7860\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f1070707730>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(cached_train, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7410939",
   "metadata": {},
   "source": [
    "## Evaluate the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fdbf8a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 4s 79ms/step - root_mean_squared_error: 1.0363 - factorized_top_k/top_1_categorical_accuracy: 0.0023 - factorized_top_k/top_5_categorical_accuracy: 0.0163 - factorized_top_k/top_10_categorical_accuracy: 0.0347 - factorized_top_k/top_50_categorical_accuracy: 0.1620 - factorized_top_k/top_100_categorical_accuracy: 0.2826 - loss: 6557.1980 - regularization_loss: 0.0000e+00 - total_loss: 6557.1980\n",
      "\n",
      "Retrieval top-100 accuracy: 0.283\n",
      "Ranking RMSE: 1.036\n"
     ]
    }
   ],
   "source": [
    "metrics = model.evaluate(cached_test, return_dict=True)\n",
    "\n",
    "print(f\"\\nRetrieval top-100 accuracy: {metrics['factorized_top_k/top_100_categorical_accuracy']:.3f}\")\n",
    "print(f\"Ranking RMSE: {metrics['root_mean_squared_error']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4012e2",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bc63c710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow_recommenders.layers.factorized_top_k.BruteForce'>\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp2teqakpl/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp2teqakpl/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to temporary directory: /tmp/tmp2teqakpl\n",
      "Top 3 recommendations for user 1:\n",
      "\n",
      "1. So I Married an Axe Murderer (1993)\n",
      "2. Star Trek III: The Search for Spock (1984)\n",
      "3. Ed Wood (1994)\n",
      "Model directory is: /tmp/tmp2teqakpl\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "import shutil\n",
    "\n",
    "def predict_movie(user, top_n=3):\n",
    "    # Create a persistent temporary directory\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "\n",
    "    # Create a model that takes in raw query features\n",
    "    index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
    "    print(type(index))\n",
    "\n",
    "    # Recommends movies out of the entire movies dataset\n",
    "    index.index_from_dataset(\n",
    "        tf.data.Dataset.zip((movies.batch(100), movies.batch(100).map(model.movie_model)))\n",
    "    )\n",
    "\n",
    "    # Get recommendations\n",
    "    _, titles = index(tf.constant([str(user)]))\n",
    "\n",
    "    # Save the model to the temporary directory\n",
    "    tf.saved_model.save(index, temp_dir)\n",
    "\n",
    "    print(f\"Model saved to temporary directory: {temp_dir}\")\n",
    "\n",
    "    print('Top {} recommendations for user {}:\\n'.format(top_n, user))\n",
    "    for i, title in enumerate(titles[0, :top_n].numpy()):\n",
    "        print('{}. {}'.format(i+1, title.decode(\"utf-8\")))\n",
    "\n",
    "    # Return the temporary directory in case you need it\n",
    "    return temp_dir\n",
    "\n",
    "# Example usage\n",
    "user_id = 1\n",
    "temp_dir = predict_movie(user_id)\n",
    "print(f\"Model directory is: {temp_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9efe8296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tmp/tmp2teqakpl'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "adb4225d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'user_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Define user embeddings or user IDs\u001b[39;00m\n\u001b[1;32m      7\u001b[0m user_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_123\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 8\u001b[0m user_embedding \u001b[38;5;241m=\u001b[39m \u001b[43muser_model\u001b[49m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39marray([user_id])})\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Call the retrieval part of the model to get top N recommendations\u001b[39;00m\n\u001b[1;32m     11\u001b[0m top_movies \u001b[38;5;241m=\u001b[39m loaded_model\u001b[38;5;241m.\u001b[39mretrieval_task\u001b[38;5;241m.\u001b[39mcall(user_embedding)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'user_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Assuming you have already trained the multitask model\n",
    "\n",
    "# Load the trained model\n",
    "loaded_model = tf.saved_model.load(temp_dir)\n",
    "\n",
    "# Define user embeddings or user IDs\n",
    "user_id = \"user_123\"\n",
    "user_embedding = user_model({\"user_id\": np.array([user_id])})\n",
    "\n",
    "# Call the retrieval part of the model to get top N recommendations\n",
    "top_movies = loaded_model.retrieval_task.call(user_embedding)\n",
    "\n",
    "# Get the movie titles from the indices\n",
    "top_movie_titles = [movie_dataset[index] for index in top_movies.indices]\n",
    "print(\"Recommended Movies: \", top_movie_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68775d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc0cf0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c509f42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aafbea8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7802f41d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd6031a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_movie(13, top_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866760eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ratings = pd.DataFrame({\n",
    "    'movie': ['Movie 1', 'Movie 2', 'Movie 3', 'Movie 4'],\n",
    "    'rating': [5, 4, 5, 2]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d096cfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_to_id = {\n",
    "    'Movie 1': 1,\n",
    "    'Movie 2': 2,\n",
    "    'Movie 3': 3,\n",
    "    'Movie 4': 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7350b993",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ratings['movie_id'] = user_ratings['movie'].map(movie_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834ee770",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_movie_ids = user_ratings['movie_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbcb748",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predicted_movies = model(user_movie_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2244a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tempfile.TemporaryDirectory() as tmp:\n",
    "  path = os.path.join(tmp, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6720b0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def predict_rating(user, movie):\n",
    "    trained_movie_embeddings, trained_user_embeddings, predicted_rating = model({\n",
    "          \"userId\": np.array([str(user)]),\n",
    "          \"original_title\": np.array([movie])\n",
    "      })\n",
    "    print(\"Predicted rating for {}: {}\".format(movie, predicted_rating.numpy()[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd364eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_movie(user=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133cf0bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497fb314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load it back; can also be done in TensorFlow Serving.\n",
    "loaded = tf.saved_model.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234d498e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass a user id in, get top predicted movie titles back.\n",
    "scores, titles = loaded([\"42\"])\n",
    "\n",
    "print(f\"Recommendations: {titles[0][:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8804a909",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d4cd2d",
   "metadata": {},
   "source": [
    "# this below somewhat worked so worth to investigate further!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ceda098",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "# Example user ratings\n",
    "user_ratings = pd.DataFrame({\n",
    "    'movie': ['Movie 1', 'Movie 2', 'Movie 3', 'Movie 4'],\n",
    "    'rating': [5, 4, 5, 2]\n",
    "})\n",
    "\n",
    "# Load the saved model (the user and movie models)\n",
    "loaded_model = model\n",
    "\n",
    "# Recreate the BruteForce index using the loaded user and movie models\n",
    "index = tfrs.layers.factorized_top_k.BruteForce(loaded_model.user_model)\n",
    "\n",
    "# Replace with your full movie dataset (ensure it contains enough movies)\n",
    "movies = movies  # At least 5 movies\n",
    "\n",
    "# Recreate the index\n",
    "index.index_from_dataset(\n",
    "  tf.data.Dataset.from_tensor_slices(movies).batch(100).map(lambda x: (x, loaded_model.movie_model(x)))\n",
    ")\n",
    "\n",
    "# Generate recommendations for a user (dummy or real user ID)\n",
    "user_id = tf.constant([\"dummy_user\"])  # Replace with actual user ID if available\n",
    "\n",
    "# Adjust the number of recommendations to match the number of available movies\n",
    "_, recommended_movie_titles = index(user_id, k=5)  # Adjust k to the available number of movies\n",
    "\n",
    "# Output the recommended movie titles\n",
    "print(\"Recommended movies:\", recommended_movie_titles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f697272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Example user ratings\n",
    "user_ratings = pd.DataFrame({\n",
    "    'movie': ['Movie 1', 'Movie 2', 'Movie 3', 'Movie 4'],\n",
    "    'rating': [5, 4, 5, 2]\n",
    "})\n",
    "\n",
    "# Load your trained TFRS model\n",
    "model = loaded\n",
    "\n",
    "# Define a function to create a weighted user profile\n",
    "def create_user_profile(model, movie_titles, ratings):\n",
    "    weighted_embeddings = []\n",
    "    \n",
    "    # Loop through each movie and rating\n",
    "    for movie_title, rating in zip(movie_titles, ratings):\n",
    "        # Get the movie's embedding by passing the movie title through the model\n",
    "        movie_embedding = model(tf.constant([movie_title]))  # Adjust to match your model's interface\n",
    "        \n",
    "        # Weight the embedding by the rating\n",
    "        weighted_embedding = movie_embedding * rating\n",
    "        weighted_embeddings.append(weighted_embedding)\n",
    "    \n",
    "    # Combine weighted embeddings (average them for simplicity)\n",
    "    user_profile_embedding = tf.reduce_mean(weighted_embeddings, axis=0)\n",
    "    \n",
    "    return user_profile_embedding\n",
    "\n",
    "# Create a user profile based on rated movies\n",
    "user_profile = create_user_profile(model, user_ratings['movie'].values, user_ratings['rating'].values)\n",
    "\n",
    "# Output the user profile embedding\n",
    "print(\"User profile embedding:\", user_profile)\n",
    "\n",
    "# Now use this user profile to get recommendations\n",
    "# You can pass this user profile to your model to get recommendations (depends on the structure of your model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a005804c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load your trained TFRS model\n",
    "model = loaded\n",
    "\n",
    "# Create input features (user_id only)\n",
    "input_features = tf.constant([\"dummy_user\"])  # Dummy user ID for a new user\n",
    "\n",
    "# Pass the input features into the model to get recommendations\n",
    "predicted_movies = model(input_features)\n",
    "\n",
    "# Output the recommendations\n",
    "print(\"Recommended movies:\", predicted_movies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1210ecea",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features = tf.constant([\"Movie 1\"])  # Example of passing a movie title\n",
    "predicted_movies = model(input_features)\n",
    "print(\"Recommended movies similar to 'Movie 1':\", predicted_movies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99138f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1175ba8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67df37a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c53ea49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1' # Set deterministic ops for TensorFlow"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
